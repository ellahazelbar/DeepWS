{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "from torch.utils.data import Dataset, DataLoader\n", "from torchvision import transforms\n", "import numpy as np\n", "from tqdm import tqdm\n", "import sys\n", "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n", "from models.cnn_lstm import ASLTranslator, ASLDataLoader\n", "from models.resnet50_bilstm import ResNet50BiLSTM"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ASLDataset(Dataset):\n", "    def __init__(self, data_dir, transform=None):\n", "        self.data_dir = data_dir\n", "        self.transform = transform\n", "        self.classes = sorted(os.listdir(data_dir))\n", "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n", "        \n", "        self.samples = []\n", "        for class_name in self.classes:\n", "            class_dir = os.path.join(data_dir, class_name)\n", "            for video_file in os.listdir(class_dir):\n", "                if video_file.endswith(('.mp4', '.avi', '.mov')):\n", "                    self.samples.append((os.path.join(class_dir, video_file), class_name))\n", "    \n", "    def __len__(self):\n", "        return len(self.samples)\n", "    \n", "    def __getitem__(self, idx):\n", "        video_path, class_name = self.samples[idx]\n", "        loader = ASLDataLoader(video_path, self.transform)\n", "        frames = loader.load_video()\n", "        label = self.class_to_idx[class_name]\n", "        return frames, label"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def collate_fn_padd(batch):\n", "    # Find the maximum length of sequences in the batch (first dimension)\n", "    max_len = max([item[0].size(0) for item in batch])\n\n", "    # Find the maximum size of the last dimension across all tensors in the batch\n", "    max_last_dim = max([item[0].size(-1) for item in batch])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # Pad the sequences to the maximum length and the last dimension to the maximum size\n", "    padded_inputs = []\n", "    labels = []\n", "    for inputs, label in batch:\n", "        padding_size_seq = max_len - inputs.size(0)\n", "        padding_size_last_dim = max_last_dim - inputs.size(-1)\n\n", "        # Pad the first dimension (sequence length) and the last dimension\n", "        # The padding order is (pad_left_dim_0, pad_right_dim_0, pad_left_dim_1, pad_right_dim_1, ...)\n", "        # Since we only want to pad the first and last dimensions on the right, the padding tuple is (0, padding_size_last_dim, 0, 0, 0, 0, 0, padding_size_seq) for a 4D tensor\n", "        # However, the documentation for F.pad is (pad_left, pad_right, pad_top, pad_bottom, pad_front, pad_back) for 3D, and it extends for higher dimensions.\n", "        # For a 4D tensor [seq_len, channels, height, width], padding (last_dim, second_to_last_dim, ...)\n", "        # We want to pad the first dimension (seq_len) and the last dimension (width)\n", "        # The padding order for a 4D tensor is (pad_left_dim3, pad_right_dim3, pad_left_dim2, pad_right_dim2, pad_left_dim1, pad_right_dim1, pad_left_dim0, pad_right_dim0)\n", "        # So to pad the first (seq_len) and last (width) dimensions on the right: (0, padding_size_last_dim, 0, 0, 0, 0, 0, padding_size_seq)\n", "        padded_input = torch.nn.functional.pad(inputs, (0, padding_size_last_dim, 0, 0, 0, 0, 0, padding_size_seq))\n", "        padded_inputs.append(padded_input)\n", "        labels.append(label)\n\n", "    # Stack the padded inputs and labels\n", "    return torch.stack(padded_inputs), torch.tensor(labels)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n", "    best_val_acc = 0.0\n", "    \n", "    for epoch in range(num_epochs):\n", "        # Training phase\n", "        model.train()\n", "        running_loss = 0.0\n", "        correct = 0\n", "        total = 0\n", "        \n", "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n", "        for inputs, labels in train_pbar:\n", "            inputs = inputs.to(device)\n", "            labels = labels.to(device)\n", "            \n", "            optimizer.zero_grad()\n", "            outputs = model(inputs)\n", "            loss = criterion(outputs, labels)\n", "            loss.backward()\n", "            optimizer.step()\n", "            \n", "            running_loss += loss.item()\n", "            _, predicted = outputs.max(1)\n", "            total += labels.size(0)\n", "            correct += predicted.eq(labels).sum().item()\n", "            \n", "            train_pbar.set_postfix({'loss': running_loss/total, 'acc': 100.*correct/total})\n", "        \n", "        # Validation phase\n", "        model.eval()\n", "        val_loss = 0.0\n", "        val_correct = 0\n", "        val_total = 0\n", "        \n", "        with torch.no_grad():\n", "            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')\n", "            for inputs, labels in val_pbar:\n", "                inputs = inputs.to(device)\n", "                labels = labels.to(device)\n", "                \n", "                outputs = model(inputs)\n", "                loss = criterion(outputs, labels)\n", "                \n", "                val_loss += loss.item()\n", "                _, predicted = outputs.max(1)\n", "                val_total += labels.size(0)\n", "                val_correct += predicted.eq(labels).sum().item()\n", "                \n", "                val_pbar.set_postfix({'loss': val_loss/val_total, 'acc': 100.*val_correct/val_total})\n", "        \n", "        val_acc = 100. * val_correct / val_total\n", "        if val_acc > best_val_acc:\n", "            best_val_acc = val_acc\n", "            torch.save(model.state_dict(), 'models/best_model.pth')\n", "            print(f'New best model saved with validation accuracy: {val_acc:.2f}%')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    # Set device\n", "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "    print(f'Using device: {device}')\n", "    \n", "    # Data transforms\n", "    transform = transforms.Compose([\n", "        transforms.ToPILImage(),\n", "        transforms.Resize((224, 224)),\n", "        transforms.ToTensor(),\n", "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n", "    ])\n", "    \n", "    # Create datasets\n", "    data_dir = 'data/processed'\n", "    dataset = ASLDataset(data_dir, transform=transform)\n", "    \n", "    # Split dataset\n", "    train_size = int(0.8 * len(dataset))\n", "    val_size = len(dataset) - train_size\n", "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n", "    \n", "    # Create data loaders\n", "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, collate_fn=collate_fn_padd)\n", "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4, collate_fn=collate_fn_padd)\n", "    \n", "    # Initialize model\n", "    num_classes = len(dataset.classes)\n", "    model = ResNet50BiLSTM(num_classes=num_classes).to(device)\n", "    \n", "    # Loss function and optimizer\n", "    criterion = nn.CrossEntropyLoss()\n", "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n", "    \n", "    # Train the model\n", "    num_epochs = 50\n", "    train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    main() "]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}